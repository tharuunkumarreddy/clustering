name: Clustering Model Validation Gate Component (Improved)
description: |
  Quality gate for clustering models that checks if a trained model meets minimum quality thresholds
  before approving it for deployment. Validates silhouette score, separation ratio, Davies-Bouldin index,
  cluster sizes, and noise percentage against configurable thresholds.
  
  Simplified version with JSON thresholds input instead of individual parameters.

inputs:
  - name: evaluation_results
    type: Data
    description: 'Evaluation results JSON from model evaluation component'
  - name: thresholds
    type: String
    description: 'Quality thresholds as JSON string (e.g., {"silhouette_min": 0.5, "separation_ratio_min": 2.0}). Uses defaults if empty.'
    default: '{}'

outputs:
  - name: validation_result
    type: Data
    description: 'Detailed validation results with decision and checks (JSON format)'
  - name: deploy_approved
    type: String
    description: 'Simple deployment approval flag (true/false)'

implementation:
  container:
    image: nikhilv215/nesy-factory:v23
    command:
      - python3
      - -u
      - -c
      - |
        import argparse
        import json
        import os
        from datetime import datetime
        from typing import Dict, List, Tuple, Any
        
        
        class ValidationGate:
            
            def __init__(self, thresholds):
                self.thresholds = thresholds
                self.checks = []
                self.failed_checks = []
            
            def run_checks(self, evaluation_metrics):
                print("\n" + "="*80)
                print("VALIDATION GATE - MODEL QUALITY CHECK")
                print("="*80)
                
                self.checks = []
                self.failed_checks = []
                
                self._check_silhouette(evaluation_metrics)
                self._check_separation_ratio(evaluation_metrics)
                self._check_davies_bouldin(evaluation_metrics)
                self._check_cluster_sizes(evaluation_metrics)
                self._check_noise_percentage(evaluation_metrics)
                
                all_passed = len(self.failed_checks) == 0
                
                print("\n" + "="*80)
                if all_passed:
                    print("VALIDATION GATE: APPROVED FOR DEPLOYMENT")
                    decision_reason = "All quality checks passed"
                    recommendation = "Model is ready for production deployment"
                else:
                    print("VALIDATION GATE: REJECTED - QUALITY ISSUES DETECTED")
                    decision_reason = 'Failed ' + str(len(self.failed_checks)) + ' checks'
                    recommendation = "Retrain model with different parameters or algorithm"
                print("="*80)
                
                result = {
                    'deploy_approved': all_passed,
                    'checks_passed': len([c for c in self.checks if c['passed']]),
                    'checks_total': len(self.checks),
                    'checks_failed': len(self.failed_checks),
                    'failed_checks': self.failed_checks,
                    'all_checks': self.checks,
                    'decision_reason': decision_reason,
                    'recommendation': recommendation,
                    'timestamp': datetime.now().isoformat(),
                    'thresholds_used': self.thresholds
                }
                
                return result
            
            def _check_silhouette(self, metrics):
                metric_name = 'Silhouette Score'
                
                internal_metrics = metrics.get('internal_metrics', {})
                value = internal_metrics.get('silhouette_score')
                threshold = self.thresholds.get('silhouette_min', 0.25)
                
                if value is not None:
                    passed = value >= threshold
                    status = 'PASS' if passed else 'FAIL'
                else:
                    passed = False
                    status = 'MISSING'
                
                check = {
                    'name': metric_name,
                    'value': value,
                    'threshold': '>= ' + str(threshold),
                    'passed': passed,
                    'status': status
                }
                self.checks.append(check)
                
                if not passed:
                    if value is not None:
                        self.failed_checks.append(metric_name + ': ' + str(round(value, 3)) + ' < ' + str(threshold))
                    else:
                        self.failed_checks.append(metric_name + ': Missing')
                
                print('')
                print('Check 1:', metric_name)
                if value is not None:
                    print('  Value:', round(value, 4))
                else:
                    print('  Value: N/A')
                print('  Threshold: >=', threshold)
                print('  Status:', status)
                if not passed and value is not None:
                    print('  Warning: Quality too low for production!')
            
            def _check_separation_ratio(self, metrics):
                metric_name = 'Separation Ratio'
                
                cluster_quality = metrics.get('cluster_quality', {})
                value = cluster_quality.get('separation_ratio')
                threshold = self.thresholds.get('separation_ratio_min', 1.5)
                
                if value is not None:
                    passed = value >= threshold
                    status = 'PASS' if passed else 'FAIL'
                else:
                    passed = False
                    status = 'MISSING'
                
                check = {
                    'name': metric_name,
                    'value': value,
                    'threshold': '>= ' + str(threshold),
                    'passed': passed,
                    'status': status
                }
                self.checks.append(check)
                
                if not passed:
                    if value is not None:
                        self.failed_checks.append(metric_name + ': ' + str(round(value, 3)) + ' < ' + str(threshold))
                    else:
                        self.failed_checks.append(metric_name + ': Missing')
                
                print('')
                print('Check 2:', metric_name)
                if value is not None:
                    print('  Value:', round(value, 4))
                else:
                    print('  Value: N/A')
                print('  Threshold: >=', threshold)
                print('  Status:', status)
                if not passed and value is not None:
                    print('  Warning: Clusters not well separated!')
            
            def _check_davies_bouldin(self, metrics):
                metric_name = 'Davies-Bouldin Index'
                
                internal_metrics = metrics.get('internal_metrics', {})
                value = internal_metrics.get('davies_bouldin_score')
                threshold = self.thresholds.get('davies_bouldin_max', 2.0)
                
                if value is not None:
                    passed = value <= threshold
                    status = 'PASS' if passed else 'FAIL'
                else:
                    passed = False
                    status = 'MISSING'
                
                check = {
                    'name': metric_name,
                    'value': value,
                    'threshold': '<= ' + str(threshold),
                    'passed': passed,
                    'status': status
                }
                self.checks.append(check)
                
                if not passed:
                    if value is not None:
                        self.failed_checks.append(metric_name + ': ' + str(round(value, 3)) + ' > ' + str(threshold))
                    else:
                        self.failed_checks.append(metric_name + ': Missing')
                
                print('')
                print('Check 3:', metric_name)
                if value is not None:
                    print('  Value:', round(value, 4))
                else:
                    print('  Value: N/A')
                print('  Threshold: <=', threshold)
                print('  Status:', status)
                if not passed and value is not None:
                    print('  Warning: Clusters overlap too much!')
            
            def _check_cluster_sizes(self, metrics):
                metric_name = 'Minimum Cluster Size'
                
                basic_stats = metrics.get('basic_statistics', {})
                cluster_sizes = basic_stats.get('cluster_sizes', {})
                
                if cluster_sizes:
                    value = min(cluster_sizes.values())
                    threshold = self.thresholds.get('min_cluster_size', 5)
                    passed = value >= threshold
                    status = 'PASS' if passed else 'FAIL'
                else:
                    value = None
                    threshold = self.thresholds.get('min_cluster_size', 5)
                    passed = False
                    status = 'MISSING'
                
                check = {
                    'name': metric_name,
                    'value': value,
                    'threshold': '>= ' + str(threshold),
                    'passed': passed,
                    'status': status
                }
                self.checks.append(check)
                
                if not passed:
                    if value is not None:
                        self.failed_checks.append(metric_name + ': ' + str(value) + ' < ' + str(threshold))
                    else:
                        self.failed_checks.append(metric_name + ': Missing')
                
                print('')
                print('Check 4:', metric_name)
                if value is not None:
                    print('  Value:', value)
                else:
                    print('  Value: N/A')
                print('  Threshold: >=', threshold)
                print('  Status:', status)
                if not passed and value is not None:
                    print('  Warning: Cluster too small - may not be meaningful!')
            
            def _check_noise_percentage(self, metrics):
                metric_name = 'Noise Percentage'
                
                basic_stats = metrics.get('basic_statistics', {})
                value = basic_stats.get('noise_percentage', 0.0)
                threshold = self.thresholds.get('max_noise_percentage', 10.0)
                
                passed = value <= threshold
                status = 'PASS' if passed else 'FAIL'
                
                check = {
                    'name': metric_name,
                    'value': value,
                    'threshold': '<= ' + str(threshold) + '%',
                    'passed': passed,
                    'status': status
                }
                self.checks.append(check)
                
                if not passed:
                    self.failed_checks.append(metric_name + ': ' + str(round(value, 1)) + '% > ' + str(threshold) + '%')
                
                print('')
                print('Check 5:', metric_name)
                print('  Value:', str(round(value, 2)) + '%')
                print('  Threshold: <=', str(threshold) + '%')
                print('  Status:', status)
                if not passed:
                    print('  Warning: Too many noise points!')
        
        
        def load_evaluation_results(filepath):
            print('')
            print('Loading evaluation results from:', filepath)
            
            if not os.path.exists(filepath):
                raise FileNotFoundError('Evaluation results not found: ' + str(filepath))
            
            with open(filepath, 'r') as f:
                results = json.load(f)
            
            print('Loaded successfully')
            return results
        
        
        def parse_thresholds(thresholds_json):
            default_thresholds = {
                'silhouette_min': 0.25,
                'separation_ratio_min': 1.5,
                'davies_bouldin_max': 2.0,
                'min_cluster_size': 5,
                'max_noise_percentage': 10.0
            }
            
            try:
                if thresholds_json and thresholds_json.strip() and thresholds_json != '{}':
                    custom_thresholds = json.loads(thresholds_json)
                    print('')
                    print('Custom thresholds provided')
                    for key, value in custom_thresholds.items():
                        print(' ', key + ':', value)
                    
                    thresholds = {**default_thresholds, **custom_thresholds}
                else:
                    print('')
                    print('Using default thresholds')
                    thresholds = default_thresholds
            except json.JSONDecodeError as e:
                print('')
                print('Warning: Invalid JSON in thresholds, using defaults')
                print('Error:', e)
                thresholds = default_thresholds
            
            print('')
            print("Quality Thresholds:")
            for key, value in thresholds.items():
                print(' ', key + ':', value)
            
            return thresholds
        
        
        def save_validation_result(result, output_path, flag_path):
            os.makedirs(os.path.dirname(output_path), exist_ok=True)
            os.makedirs(os.path.dirname(flag_path), exist_ok=True)
            
            with open(output_path, 'w') as f:
                json.dump(result, f, indent=2)
            
            file_size = os.path.getsize(output_path) / 1024
            
            print('')
            print('Validation result saved')
            print('  File:', output_path)
            print('  Size:', str(round(file_size, 2)), 'KB')
            
            with open(flag_path, 'w') as f:
                f.write(str(result['deploy_approved']).lower())
            
            print('  Flag:', flag_path, '->', result['deploy_approved'])
        
        
        def print_summary(result):
            print("\n" + "="*80)
            print("VALIDATION SUMMARY")
            print("="*80)
            
            print('')
            print('Checks Passed:', str(result['checks_passed']) + '/' + str(result['checks_total']))
            print('Deploy Approved:', 'YES' if result['deploy_approved'] else 'NO')
            print('Decision:', result['decision_reason'])
            
            if result['failed_checks']:
                print('')
                print('Failed Checks:')
                for check in result['failed_checks']:
                    print('  -', check)
            
            print('')
            print('Recommendation:')
            print(' ', result['recommendation'])
            
            print("="*80)
        
        
        def main():
            parser = argparse.ArgumentParser(
                description='Validation Gate for Clustering Models'
            )
            
            parser.add_argument('--evaluation_results', required=True,
                               help='Path to evaluation results JSON')
            parser.add_argument('--thresholds', default='{}',
                               help='Thresholds as JSON string')
            
            parser.add_argument('--output_validation_result', required=True,
                               help='Output path for validation result JSON')
            parser.add_argument('--output_deploy_approved', required=True,
                               help='Output path for deploy approval flag')
            
            args = parser.parse_args()
            
            try:
                print("="*80)
                print("VALIDATION GATE FOR CLUSTERING")
                print("="*80)
                
                evaluation_results = load_evaluation_results(args.evaluation_results)
                
                thresholds = parse_thresholds(args.thresholds)
                
                gate = ValidationGate(thresholds)
                result = gate.run_checks(evaluation_results)
                
                save_validation_result(
                    result,
                    args.output_validation_result,
                    args.output_deploy_approved
                )
                
                print_summary(result)
                
                if result['deploy_approved']:
                    print("\nVALIDATION PASSED - Model approved for deployment")
                else:
                    print("\nVALIDATION FAILED - Model rejected")
                
                print("="*80)
                
            except Exception as e:
                print('')
                print('ERROR:', str(e))
                import traceback
                traceback.print_exc()
                result = {
                    'deploy_approved': False,
                    'error': str(e)
                }
                os.makedirs(os.path.dirname(args.output_deploy_approved), exist_ok=True)
                with open(args.output_deploy_approved, 'w') as f:
                    f.write('false')
        
        
        if __name__ == '__main__':
            main()

    args:
      - --evaluation_results
      - {inputPath: evaluation_results}
      - --thresholds
      - {inputValue: thresholds}
      - --output_validation_result
      - {outputPath: validation_result}
      - --output_deploy_approved
      - {outputPath: deploy_approved}
